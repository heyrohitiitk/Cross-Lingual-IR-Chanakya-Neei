{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "90254039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848dd62",
   "metadata": {},
   "source": [
    "Load Hindi-Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4b5c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"final_stopwords.txt\", encoding = \"UTF-8\")\n",
    "stopWords = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766af69",
   "metadata": {},
   "source": [
    "Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "90ede766",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_h = open(\"paras_hindi.txt\", encoding = \"UTF-8\").read().split(\"\\n\\n\")\n",
    "paras_g = open(\"paras_gujrati.txt\", encoding = \"UTF-8\").read().split(\"\\n\\n\")\n",
    "paras_e = open(\"paras_english.txt\", encoding = \"UTF-8\").read().split(\"\\n\\n\")\n",
    "slokas = open(\"slokas.txt\", encoding = \"UTF-8\").read().split(\"\\n\\n\")\n",
    "with open('synonyms.pkl', 'rb') as f:\n",
    "    syns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61015678",
   "metadata": {},
   "source": [
    "Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fea885f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=[\"।\",\";\",\",\",\":\",\"!\",'\"',\"?\",\":-\",\"-\",\"{\",\"(\",\"}\",\")\",\"_\",\"०\",\"S\",\"―\",\"=\",\"[\",\"]\",\"......\",\":-\",\".\",\"॥\",'”',\"|\",\"“\",\"'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7073335",
   "metadata": {},
   "source": [
    "## Stemming Hindi Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "995465d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = {\n",
    "    1: [\"ो\", \"े\", \"ू\", \"ु\", \"ी\", \"ि\", \"ा\"],\n",
    "    2: [\"कर\", \"ाओ\", \"िए\", \"ाई\", \"ाए\", \"ने\", \"नी\", \"ना\", \"ते\", \"ीं\", \"ती\", \"ता\", \"ाँ\", \"ां\", \"ों\", \"ें\"],\n",
    "    3: [\"ाकर\", \"ाइए\", \"ाईं\", \"ाया\", \"ेगी\", \"ेगा\", \"ोगी\", \"ोगे\", \"ाने\", \"ाना\", \"ाते\", \"ाती\", \"ाता\", \"तीं\", \"ाओं\", \"ाएं\", \"ुओं\", \"ुएं\", \"ुआं\"],\n",
    "    4: [\"ाएगी\", \"ाएगा\", \"ाओगी\", \"ाओगे\", \"एंगी\", \"ेंगी\", \"एंगे\", \"ेंगे\", \"ूंगी\", \"ूंगा\", \"ातीं\", \"नाओं\", \"नाएं\", \"ताओं\", \"ताएं\", \"ियाँ\", \"ियों\", \"ियां\"],\n",
    "    5: [\"ाएंगी\", \"ाएंगे\", \"ाऊंगी\", \"ाऊंगा\", \"ाइयाँ\", \"ाइयों\", \"ाइयां\"],\n",
    "}\n",
    "\n",
    "def hi_stem(word):\n",
    "    for L in 5, 4, 3, 2, 1:\n",
    "        if len(word) > L + 1:\n",
    "            for suf in suffixes[L]:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-L]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8b77e",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "575aaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_stem(string, stopWords):\n",
    "    string = \"\".join([w if w not in punctuations else \" \" for w in string])  #To remove punctuations\n",
    "    tokens = string.split()\n",
    "    tokens = [hi_stem(word) for word in tokens if word not in stopWords]\n",
    "    tokens = [w for w in tokens if w not in stopWords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7f232",
   "metadata": {},
   "source": [
    "## Creating Posting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8145c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_col = {}\n",
    "for idx, para in enumerate(paras_h):\n",
    "    words = token_stem(para, stopWords)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in w_col.keys():\n",
    "            if idx in w_col[word].keys():\n",
    "                w_col[word][idx] += 1\n",
    "            else:\n",
    "                w_col[word][idx] = 1\n",
    "        else:\n",
    "            temp = {idx : 1}\n",
    "            w_col[word] = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c329746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(w_col, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a99be0",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3cf47862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, w_coll, l = 5, b = 0.75, k = 2):\n",
    "    q_tokens = token_stem(query, stopWords)\n",
    "    lengths = {}\n",
    "    N = len(paras_h)\n",
    "    avg_len = 0\n",
    "    for idx, para in enumerate(paras_h):\n",
    "        lengths[idx] = len(para)             #cal no of words of each file\n",
    "        avg_len += lengths[idx]\n",
    "    avg_len /= N\n",
    "    #Calculate idf of each token\n",
    "    idf = {}\n",
    "    for word in np.unique(q_tokens):\n",
    "        if word in w_coll.keys():\n",
    "            df = len(w_coll[word].keys())\n",
    "        else:\n",
    "            df = 0\n",
    "        idf[word] = np.log((N - df + 0.5) / (df + 0.5))\n",
    "    score = {}\n",
    "    for idx, para in enumerate(paras_h):\n",
    "        s = 0\n",
    "        for word in np.unique(q_tokens):\n",
    "            tf = 0\n",
    "            if word in w_coll.keys() and idx in w_coll[word].keys():\n",
    "                tf = w_coll[word][idx]\n",
    "            s += idf[word] * (tf * (k + 1)) / (k*(1 - b + b*lengths[idx]/avg_len) + tf)\n",
    "        score[idx] = s\n",
    "    return sorted(score, key = score.get, reverse=True)[:l]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac4c4a",
   "metadata": {},
   "source": [
    "## Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9967115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def get_translation(data, dest):\n",
    "    translator = Translator()\n",
    "    text = translator.translate(data, dest).text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff790f",
   "metadata": {},
   "source": [
    "## Final Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "61b91dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, w_col, lang, l = 5):\n",
    "    query = get_translation(query, \"hi\")\n",
    "    tokens = token_stem(query, stopWords)\n",
    "    for idx, token in enumerate(tokens):\n",
    "#         if token not in w_col:\n",
    "        if token in syns.keys():\n",
    "            tokens[idx] += \" \" + \" \".join([w for w in syns[token]])\n",
    "    query = \" \".join(tokens)\n",
    "#     print(query)\n",
    "    indxs = BM25(query, w_col, l)\n",
    "    print(indxs)\n",
    "    if lang == 'g':\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_g[idx]}' for idx in indxs], indxs\n",
    "    elif lang == 'e':\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_e[idx]}' for idx in indxs], indxs\n",
    "    else:\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_h[idx]}' for idx in indxs], indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dc2ea581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 282, 238, 98, 280]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['अधीत्येदं यथाशास्त्रं नरो जानाति सत्तम:।\\nधर्मोपदेशविख्यातं कार्याकार्य शुभाशु भम्\\u200c।।\\n\\nThrough the study of this manuscript, after thought and\\nreflection, even an ordinary person will gain knowledge to\\ndistinguish between capability-incompetence and\\nrightwrong. Through this manuscript, I wish to create\\nconsciousness in human beings towards good deeds versus\\nsins, morality versus immorality and duty versus\\nirresponsibility. By observing this moral behaviour, human\\nbeings should enlighten their lives. Then, the purpose of this\\nmanuscript will be fulfilled.',\n",
       "  '|| पठन्ति चतुरो वेदान्\\u200c धर्मशास्त्राण्यनेकश:।\\nआत्मानं नैव जानन्ति दर्वी पाकरसं यथा।।\\n\\nPeople, who even after studying religious scriptures\\nlike Vedas, etc. remain ignorant of its essential elements,\\nwho do not have knowledge of Soul-God, remain devoid of\\nknowledge of their own spiritual self. Chanakya has\\ncompared such persons with a ladle, which stirs the juicy\\ncurry but which remains unaware of its taste and\\nusefulness. Chanakya says that such a study is a waste.',\n",
       "  '|| राज्ञि धर्मिणि धर्मिष्ठा: पापे पापा: समे समा:।\\nराजानमनुवर्तन्ते यथा राजा तथा प्रजा:।।\\n\\nIf the king of a kingdom is religious and talented, then\\nthe subjects of that kingdom will also be religious and\\ntalented. If the king is a sinner, then his subjects will also\\nbehave accordingly; because the subjects follow the king.\\nThat is why it is said \"As the king, so are his subjects\".',\n",
       "  \"श्रुत्वा धर्म विजानाति श्रुत्वा त्यजति दुर्मतिम्\\u200c।\\nश्र॒ुत्वा ज्ञानमवाप्रोति श्रुत्वा मोक्षमवाप्रुयात्\\u200c।।\\n\\nIn this shloka, Chanakya has clarified the importance of\\nstudy and listening of the Vedic manuscripts. He says that to\\nunderstand the depth of religion, the knowledge of the Vedic\\nmanuscripts is essential. Through them, man can imbibe the\\nessence of religion in life. Vedic knowledge can even move\\nthe man's sin-filled mind towards righteousness. By its\\ninfluence, even an ordinary man can attain superiority. The\\npower of Vedic knowledge enables the saints to undertake\\nthe welfare of the world and reach heaven after death.\\nLike the study of the Vedic manuscripts is extremely\\nbeneficial, likewise listening to its recitation purifies the\\nmind. So, if the study of the manuscripts is not possible for\\nmen, then they should listen to its recitation. This will\\nenable them to understand the Vedic knowledge in greater\\ndepth.\",\n",
       "  '|| अनन्तशास्त्रं बहुलाश्व विद्या: अल्पश्च कालो\\nबहुविघ्नता च।\\nयत्सारभूत॑ तदुपासनीयं हंसो यथा\\nक्षीरमिवाम्बुमध्यात्\\u200c।।\\n\\nCommenting on knowledge, Chanakya says that this\\nworld is filled with immense knowledge. The human soul,\\neven after taking hundreds of births, cannot learn all the\\nknowledge. But like the swan can drink only the milk from\\ndiluted milk and leave the water, similarly, a man like the\\nswan should extract the essential elements like milk from\\nthe many scriptures and other studies. That is, a man\\nshould fully understand the meaning of the Vedas in the\\nshort span of his life.'],\n",
       " [1, 282, 238, 98, 280])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"studying religious scriptures like Vedas\"\n",
    "search(query, w_col, \"e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b9e22",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76d7b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = {}\n",
    "for idx, para in enumerate(paras_h):\n",
    "    lengths[idx] = len(para)\n",
    "idf = {}\n",
    "N = len(slokas)\n",
    "for word in w_col.keys():\n",
    "    df = len(w_col[word].keys())\n",
    "    idf[word] = np.log((N) / (df))\n",
    "#Calculate tf-idf score vector of each file\n",
    "norm_list = {}\n",
    "for idx, para in enumerate(paras_h):\n",
    "    for word in np.unique(para.split()):\n",
    "        tf = 0\n",
    "        try:\n",
    "            if idx in w_col[word].keys():\n",
    "                tf = w_col[word][idx] / lengths[idx]\n",
    "        except:\n",
    "            pass\n",
    "        if idx not in norm_list.keys():\n",
    "            norm_list[idx] = []\n",
    "        try:\n",
    "            norm_list[idx].append(tf * idf[word])\n",
    "        except:\n",
    "            pass\n",
    "for idx in range(N-1):\n",
    "    norm_list[idx] = np.linalg.norm(norm_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "eb6d497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates cosine similarities between document vectors and query vector\n",
    "def find_cosine_sim(n_docs, query_vector, doc_vectors):\n",
    "    cosine_sims = []\n",
    "    for i in range(n_docs-1):\n",
    "        dot = np.dot(query_vector, doc_vectors[i])\n",
    "        query_norm = np.linalg.norm(query_vector)\n",
    "        doc_norm = norm_list[i]\n",
    "        cosine_sims.append(dot/((query_norm + 0.5)*(doc_norm + 0.5)))\n",
    "    return cosine_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2adaa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned query must be sent to this model\n",
    "def tfidf(query, main_dict):\n",
    "    n_slokas = len(slokas)\n",
    "    # finding document vectors\n",
    "    tfidf_dict = {} # dictionary which stores tfidf of each document\n",
    "    doc_vectors = [] \n",
    "    for i in range(n_slokas):\n",
    "        n_words = len(paras_h[i].split())\n",
    "        vector = []\n",
    "        for word in np.unique(query):\n",
    "            if word in main_dict.keys() and i in main_dict[word].keys():\n",
    "#                 tf = main_dict[word][i]/n_words\n",
    "                tf = main_dict[word][i]\n",
    "                idf = np.log((n_slokas+1)/(len(main_dict[word].keys())+1))\n",
    "                tf_idf = tf*idf\n",
    "                vector.append(tf_idf)\n",
    "            else:\n",
    "                vector.append(0)\n",
    "        doc_vectors.append(vector)\n",
    "    word_freq_query_dict = Counter(query)\n",
    "    # finding query vector\n",
    "    query_vector = []\n",
    "    # remember np.unique return result in alphabetical order\n",
    "    for word in np.unique(query):\n",
    "        if word in main_dict.keys():\n",
    "#             tf = word_freq_query_dict[word]/len(query)\n",
    "            tf = word_freq_query_dict[word]\n",
    "            idf = np.log((n_slokas+1)/(len(main_dict[word].keys())+1))\n",
    "            tf_idf = tf*idf\n",
    "            query_vector.append(tf_idf)\n",
    "        else:\n",
    "            query_vector.append(0)\n",
    "#     print(query_vector)\n",
    "    scores = find_cosine_sim(n_slokas, query_vector, doc_vectors)\n",
    "    return sorted(np.argsort(np.array(scores))[-5:], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2ce271a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tfidf(query, w_col, lang, l = 5):\n",
    "    query = get_translation(query, \"hi\")\n",
    "    tokens = token_stem(query, stopWords)\n",
    "    for idx, token in enumerate(tokens):\n",
    "#         if token not in w_col:\n",
    "        if token in syns.keys():\n",
    "            tokens[idx] += \" \" + \" \".join([w for w in syns[token]])\n",
    "    query = \" \".join(tokens)\n",
    "    tokens = token_stem(query, stopWords)\n",
    "    indxs = tfidf(tokens, w_col)\n",
    "    print(indxs)\n",
    "    if lang == 'g':\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_g[idx]}' for idx in indxs], indxs\n",
    "    elif lang == 'e':\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_e[idx]}' for idx in indxs], indxs\n",
    "    else:\n",
    "        return [f'{slokas[idx]}\\n\\n{paras_h[idx]}' for idx in indxs], indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8b0ebea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 50, 103, 171, 186]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\"कोकिलानां स्वरो रूपं स्त्रीणां रूपं पतिव्रतम्\\u200c।\\nविद्या रूपं कुरूपाणां क्षमा रूपं तपस्विनाम्\\u200c।।\\n\\nOn the importance of attributes, Chanakya says that like\\nthe black colour of the koel bird (cuckoo) becomes\\ninsignificant on account of its melodious voice; in other\\nwords, its melodious voice depicts its character. Similarly,\\nloyalty towards her husband depicts a woman's image and\\nbeauty. An educated and intelligent ugly woman is much\\nmore beautiful than a gorgeous but a characterless woman.\\nThe attributes give her respect and status. The greatness of\\nthe hermit lies in his ability to forgive. Not losing their\\nbalance and patience, under any circumstances is the proof\\nof their true devotion. These attributes enable assessment\\nof the depth of their devotion.\",\n",
       "  'एकेना<पि सुपुत्रेण विद्यायुक्तेन साधुना।\\nआहलादितं कुलं सर्व यथा चन्द्रेण शर्वरी।।\\n\\nAs a single moon can dispel darkness-a job which\\ncannot be done, even by hundreds of stars, similarly, a\\ntalented scholar, with character and soft speech, brings\\npride to the whole family. Nobody likes a dark night;\\nsimilarly, a son devoid of any virtues is disliked by the\\nfamily. Therefore, Chanakya says that it is appropriate to\\nhave a single virtuous son in the family rather than have\\nseveral virtueless sons.',\n",
       "  'काल: पचति भूतानि काल: संहरते प्रजा:।\\nकाल: सुप्तेषु जागर्ति कालो हि दुरतिक्रम:।।\\n\\nOn time, Chanakya says that time or death is most\\npowerful. It is so powerful that it can destruct anything in\\nthis universe in no time. Even when universal destruction\\ncauses it to disappear under water, the time is ticking. Time\\ncycle is perpetually in motion. Against it even the most\\nknowledgeable persons, scholars and good souls become\\nhelpless, the brave and bold Kshatriya are defeated. All the\\nfour life stages of mankind conform to time. It is impossible\\nfor everyone to win over time. It is, therefore, imperative\\nthat mankind remains righteous and habitually performs\\ngood deeds. Through good deeds only he can set right his\\nlife in the next world.',\n",
       "  \"प्रातर्यूतप्रसंगेन मध्याहने स्त्रीप्रसंगत:।\\nरात्रौ चौर्यप्रसंगेन कालो गच्छत्यथधीमताम्\\u200c।।\\n\\nDiscussing the daily activities of a fool and an\\nintelligent person, Chanakya says that a fool's day starts\\nwith gambling. In the afternoon, they mate and their nights\\nare spent in robbing or other sinful activities. Against this a\\ngentleman's, and intelligent person's day starts with good\\ndeeds and the whole day is spent in other's welfare. So, a\\nman should use his time purposefully like a gentleman.\",\n",
       "  'विप्रो वृक्षस्तस्य मूलं च संध्या वेदाः: शाखा धर्मकर्माणि पत्रम्\\u200c।\\nतस्मान्मूलं यत्नतो रक्षणीयं छिन्ने मूले नैव शाखा न पत्रम्\\u200c।।\\n\\nGiving a form to the imaginary eternal tree, Chanakya\\nsays that the Brahmin is eternal tree on the earth. Prayers\\nare its roots and Vedas its branches. Religious ceremonies\\nare its beautiful leaves growing on the branches. He says\\nthat roots of the tree are most important, as the tree\\nsurvives on the roots. If the roots weaken or die, its does not\\ntake long for the tree to dry. So, the root must be duly\\nprotected.'],\n",
       " [43, 50, 103, 171, 186])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"काल: सुप्तेषु जागर्ति कालो हि दुरतिक्रम:\"\n",
    "search_tfidf(query, w_col, \"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ca0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
